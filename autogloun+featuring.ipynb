{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## auto-gluon ver0.8.2\n",
    "# !pip install autogluon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 라이브러리 로딩 및 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(SEED) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로딩 및 라벨 영문화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv').rename(columns={'추석까지 남은 기간(주)':'remain_week', '쇼핑몰 구분':'shop', '가격(원)':'price', '프로모션 여부':'promotion', '도시 유형':'city', '지역 유형':'region', '쇼핑몰 유형':'shop_type', '선물 유형':'gift', '수요량':'order_count' })\n",
    "test_df = pd.read_csv('test.csv').rename(columns={'추석까지 남은 기간(주)':'remain_week', '쇼핑몰 구분':'shop', '가격(원)':'price', '프로모션 여부':'promotion', '도시 유형':'city', '지역 유형':'region', '쇼핑몰 유형':'shop_type', '선물 유형':'gift', '수요량':'order_count' })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 데이터에 특성 변수 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선물세트별 수요량 변수\n",
    "gift_mean_map = train_df.groupby('gift')['order_count'].mean().to_dict()\n",
    "gift_std_map = train_df.groupby('gift')['order_count'].std().to_dict()\n",
    "# 도시별 수요량 변수\n",
    "city_mean_map = train_df.groupby('city')['order_count'].mean().to_dict()\n",
    "city_std_map = train_df.groupby('city')['order_count'].std().to_dict()\n",
    "# 쇼핑몰별 수요량 변수\n",
    "mall_mean_map = train_df.groupby('shop')['order_count'].mean().to_dict()\n",
    "mall_std_map = train_df.groupby('shop')['order_count'].std().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    df['gift_mean'] = df['gift'].map(gift_mean_map)\n",
    "    df['gift_std'] = df['gift'].map(gift_std_map)\n",
    "    \n",
    "    df['city_mean'] = df['city'].map(city_mean_map)\n",
    "    df['city_std'] = df['city'].map(city_std_map)\n",
    "\n",
    "    df['mall_mean'] = df['shop'].map(mall_mean_map)\n",
    "    df['mall_std']  = df['shop'].map(mall_std_map)\n",
    "    \n",
    "# 동일한 이름의 선물세트인데, 가격대는 두가지로 분리된 경우가 있어,\n",
    "# 이를 반영하려고 아래 항목을 추가하였으나, 실제 점수가 하락하는 현상을\n",
    "# 마지막에 확인하였으나, 제출결과에서는 반영이 안됬네요. 빼고하니, 0.4점 정도 이득이 있습니다. \n",
    "    df['gift_type'] = 0\n",
    "    gift_type_list = [\n",
    "        ('실속스팸선물세트', 50000), \n",
    "        ('행복스팸선물세트', 50000), \n",
    "        ('특선스팸선물세트', 50000), \n",
    "        ('특별한선택스팸선물세트', 95000), \n",
    "        ('한과종합선물세트', 200000), \n",
    "        ('프리미엄고당도샤인머스캣선물세트', 145000), \n",
    "    ]\n",
    "\n",
    "    for gift, price in gift_type_list:\n",
    "        selected_index = df[df.gift == gift].index\n",
    "        df.loc[selected_index, 'gift_type'] = df.loc[selected_index, 'price'] // price\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = preprocess( train_df )\n",
    "test  = preprocess( test_df )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 공용 함수 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 메시지와 점수 출력\n",
    "def print_msg(predictor, title_msg='predict', model_name=None):\n",
    "    lb = predictor.leaderboard(silent=True)\n",
    "    if model_name is None:\n",
    "        model_name = lb.model[0]\n",
    "    score_val = lb.loc[lb.model==model_name,'score_val'].iloc[0]\n",
    "    msg = f'{title_msg}\\nmodel:{model_name}\\nscore:{score_val:.2f}'\n",
    "    print(msg)\n",
    "    return score_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련 및 예측 결과 저장\n",
    "def model_fit(predictor, train_data, **kwargs):\n",
    "    predictor.fit(train_data=train_data, **kwargs)\n",
    "    title_msg = f'predict'\n",
    "    score = print_msg(predictor, title_msg, model_name=None)\n",
    "    print(f'{title_msg}: {score:.2f}')\n",
    "    model_predict( predictor, title_msg=title_msg )\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 모델로 예측 및 저장\n",
    "def model_predict(predictor, model_name = None, title_msg=None ):\n",
    "    submission = pd.read_csv('sample_submission.csv')\n",
    "    lb = predictor.leaderboard(silent=True)\n",
    "    if model_name is None:\n",
    "        model_name = lb.model[0]\n",
    "    if title_msg is None:\n",
    "        title_msg = model_name.lower()\n",
    "    pred = predictor.predict( test.drop(columns='ID'), model=model_name )\n",
    "    submission['수요량'] = pred\n",
    "    print(submission.head())\n",
    "    from datetime import datetime\n",
    "    time_str = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    save_filename = f'./submit_{title_msg}_{time_str}.csv'\n",
    "    submission.to_csv(save_filename, index = False)\n",
    "    print(f'file saved : {save_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataAugmentation 기법을 적용 결과 저장\n",
    "def model_distill(predictor):\n",
    "    hyperparameters = {'GBM':{}}\n",
    "    size_factors=[None,5]\n",
    "    scores = []\n",
    "    for size_factor in size_factors:\n",
    "        if size_factor is None:\n",
    "            distill_models = predictor.distill(hyperparameters=hyperparameters, augment_method=None)\n",
    "        else:\n",
    "            distill_models = predictor.distill(hyperparameters=hyperparameters, augment_method='spunge', augment_args={'size_factor': size_factor} )\n",
    "    \n",
    "        model_name = distill_models[0]\n",
    "        title_msg = f'DSTLx{size_factor}'\n",
    "        scores.append( print_msg(predictor, title_msg, model_name=model_name) )\n",
    "        model_predict( predictor, model_name=model_name, title_msg=title_msg )\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 훈련 및 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231004_052546/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=2, num_bag_folds=8, num_bag_sets=3\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231004_052546/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.17\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #224-Ubuntu SMP Mon Jun 19 13:30:12 UTC 2023\n",
      "Disk Space Avail:   80.72 GB / 121.67 GB (66.3%)\n",
      "Train Data Rows:    5872\n",
      "Train Data Columns: 15\n",
      "Label Column: order_count\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15967.08 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.57 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 6 | ['gift_mean', 'gift_std', 'city_mean', 'city_std', 'mall_mean', ...]\n",
      "\t\t('int', [])    : 4 | ['remain_week', 'price', 'promotion', 'gift_type']\n",
      "\t\t('object', []) : 5 | ['shop', 'city', 'region', 'shop_type', 'gift']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 5 | ['shop', 'city', 'region', 'shop_type', 'gift']\n",
      "\t\t('float', [])     : 6 | ['gift_mean', 'gift_std', 'city_mean', 'city_std', 'mall_mean', ...]\n",
      "\t\t('int', [])       : 2 | ['remain_week', 'price']\n",
      "\t\t('int', ['bool']) : 2 | ['promotion', 'gift_type']\n",
      "\t0.1s = Fit runtime\n",
      "\t15 features in original data used to generate 15 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.42 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 3 stack levels (L1 to L3) ...\n",
      "Excluded models: ['CAT', 'NN_TORCH'] (Specified by `excluded_model_types`)\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t-189.602\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t-188.9809\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 24 child models (S1F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-136.4535\t = Validation score   (-root_mean_squared_error)\n",
      "\t17.59s\t = Training   runtime\n",
      "\t1.82s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 24 child models (S1F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-122.3893\t = Validation score   (-root_mean_squared_error)\n",
      "\t21.23s\t = Training   runtime\n",
      "\t2.5s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t-127.8139\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.79s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\t-127.377\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.91s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 24 child models (S1F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-120.9804\t = Validation score   (-root_mean_squared_error)\n",
      "\t51.42s\t = Training   runtime\n",
      "\t0.69s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 24 child models (S1F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-121.8179\t = Validation score   (-root_mean_squared_error)\n",
      "\t29.24s\t = Training   runtime\n",
      "\t0.92s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 24 child models (S1F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-121.7802\t = Validation score   (-root_mean_squared_error)\n",
      "\t59.52s\t = Training   runtime\n",
      "\t9.12s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-114.8996\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['CAT', 'NN_TORCH'] (Specified by `excluded_model_types`)\n",
      "Fitting 7 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tFitting 24 child models (S1F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-124.1084\t = Validation score   (-root_mean_squared_error)\n",
      "\t13.49s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 24 child models (S1F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-122.893\t = Validation score   (-root_mean_squared_error)\n",
      "\t13.47s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\t-119.9846\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.21s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\t-117.554\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.43s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tFitting 24 child models (S1F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-117.5992\t = Validation score   (-root_mean_squared_error)\n",
      "\t46.88s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tFitting 24 child models (S1F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-120.7138\t = Validation score   (-root_mean_squared_error)\n",
      "\t18.66s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tFitting 24 child models (S1F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-119.1597\t = Validation score   (-root_mean_squared_error)\n",
      "\t25.58s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-115.6828\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['CAT', 'NN_TORCH'] (Specified by `excluded_model_types`)\n",
      "Fitting 7 L3 models ...\n",
      "Fitting model: LightGBMXT_BAG_L3 ...\n",
      "\tFitting 24 child models (S1F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-125.7287\t = Validation score   (-root_mean_squared_error)\n",
      "\t13.34s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L3 ...\n",
      "\tFitting 24 child models (S1F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-126.1497\t = Validation score   (-root_mean_squared_error)\n",
      "\t13.39s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L3 ...\n",
      "\t-121.6317\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.56s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L3 ...\n",
      "\t-119.3867\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.34s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L3 ...\n",
      "\tFitting 24 child models (S1F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-120.0081\t = Validation score   (-root_mean_squared_error)\n",
      "\t47.31s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L3 ...\n",
      "\tFitting 24 child models (S1F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-124.1216\t = Validation score   (-root_mean_squared_error)\n",
      "\t18.03s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L3 ...\n",
      "\tFitting 24 child models (S1F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-123.3983\t = Validation score   (-root_mean_squared_error)\n",
      "\t24.09s\t = Training   runtime\n",
      "\t0.78s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L4 ...\n",
      "\t-118.1741\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 464.13s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231004_052546/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict\n",
      "model:WeightedEnsemble_L2\n",
      "score:-114.90\n",
      "predict: -114.90\n",
      "          ID         수요량\n",
      "0  TEST_0000  203.106400\n",
      "1  TEST_0001   42.830845\n",
      "2  TEST_0002  350.928070\n",
      "3  TEST_0003  174.663818\n",
      "4  TEST_0004  249.217163\n",
      "file saved : ./submit_predict_20231004_143349.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-114.89955418023898"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best_quality를 지정하면, bag_fold=8, bag_sets=1로 지정되는 데, bag_sets을 늘리는게 점수를 좋게 받았습니다. \n",
    "fit_parameters = {\n",
    "    'presets': 'best_quality',\n",
    "    'num_bag_folds': 8,  ### 값을 키울수록 점수가 좋아지나, 너무 키우면 검증세트 크기가 작아져 잘못된 결과를 얻게 됨\n",
    "    'num_bag_sets': 3,  ### 값을 키울수록 점수가 좋아짐, 속도가 느려짐.\n",
    "    'num_stack_levels': 2,  ### 2번이 의미가 없어, 1번만 해도 됨\n",
    "    'excluded_model_types': ['CAT', 'NN_TORCH', ],  ### 속도가 느린 모델은 제외시켰습니다.\n",
    "}\n",
    "\n",
    "predictor = TabularPredictor(problem_type='regression', label='order_count', eval_metric='rmse', sample_weight='auto_weight')\n",
    "model_fit( predictor, train_data=train.drop(columns=['ID']), **fit_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Distilling with teacher='WeightedEnsemble_L2', teacher_preds=soft, augment_method=None ...\n",
      "Distilling with each of these student models: ['LightGBM_DSTL']\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_DSTL ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 105.763\n",
      "[2000]\tvalid_set's rmse: 105.125\n",
      "[3000]\tvalid_set's rmse: 105.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-105.0206\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.29s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Distilling with each of these student models: ['WeightedEnsemble_L2_DSTL']\n",
      "Fitting model: WeightedEnsemble_L2_DSTL ...\n",
      "\t-105.0206\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Distilled model leaderboard:\n",
      "                      model   score_val  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0             LightGBM_DSTL -105.020638       0.058983  3.287784                0.058983           3.287784            1       True         27\n",
      "1  WeightedEnsemble_L2_DSTL -105.020638       0.059355  3.290339                0.000372           0.002556            2       True         28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSTLxNone\n",
      "model:LightGBM_DSTL\n",
      "score:-105.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Distilling with teacher='WeightedEnsemble_L2', teacher_preds=soft, augment_method=spunge ...\n",
      "SPUNGE: Augmenting training data with 26420 synthetic samples for distillation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID         수요량\n",
      "0  TEST_0000  237.418594\n",
      "1  TEST_0001   38.506824\n",
      "2  TEST_0002  326.258331\n",
      "3  TEST_0003  177.262268\n",
      "4  TEST_0004  189.185791\n",
      "file saved : ./submit_DSTLxNone_20231004_143416.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Distilling with each of these student models: ['LightGBM_2_DSTL']\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_2_DSTL ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 102.035\n",
      "[2000]\tvalid_set's rmse: 99.4658\n",
      "[3000]\tvalid_set's rmse: 98.3735\n",
      "[4000]\tvalid_set's rmse: 97.9612\n",
      "[5000]\tvalid_set's rmse: 97.6781\n",
      "[6000]\tvalid_set's rmse: 97.4859\n",
      "[7000]\tvalid_set's rmse: 97.3972\n",
      "[8000]\tvalid_set's rmse: 97.2813\n",
      "[9000]\tvalid_set's rmse: 97.2761\n",
      "[10000]\tvalid_set's rmse: 97.2772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-97.2479\t = Validation score   (-root_mean_squared_error)\n",
      "\t13.59s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Distilling with each of these student models: ['WeightedEnsemble_2_L2_DSTL']\n",
      "Fitting model: WeightedEnsemble_2_L2_DSTL ...\n",
      "\t-97.2479\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Distilled model leaderboard:\n",
      "                        model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0             LightGBM_2_DSTL -97.247944       0.198548  13.589706                0.198548          13.589706            1       True         29\n",
      "1  WeightedEnsemble_2_L2_DSTL -97.247944       0.199022  13.592421                0.000473           0.002714            2       True         30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSTLx5\n",
      "model:LightGBM_2_DSTL\n",
      "score:-97.25\n",
      "          ID         수요량\n",
      "0  TEST_0000  226.371185\n",
      "1  TEST_0001   55.560329\n",
      "2  TEST_0002  384.381836\n",
      "3  TEST_0003  173.837433\n",
      "4  TEST_0004  228.028076\n",
      "file saved : ./submit_DSTLx5_20231004_143656.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-105.0206377368004, -97.24794392918379]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 Augmentation 을 위해 distillation 적용\n",
    "model_distill( predictor )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
